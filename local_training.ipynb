{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxlsP_OnMk6"
      },
      "source": [
        "Adapted from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerwenAI/spaCy_tuTorial/blob/master/BERT_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_xc_chh6VBQ"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%` not found.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import spacy\n",
        "from spacy.tokens import Span\n",
        "from spacy.tokens import DocBin\n",
        "from numpy import random\n",
        "import spacy_transformers\n",
        "np.random.seed(42) \n",
        "\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 1: Argument detect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_UkeC7SG2krJ"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'FilePath' from 'pandas._typing' (/Users/danielbradley/opt/anaconda3/lib/python3.8/site-packages/pandas/_typing.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/9z/tw9j8p_n7w3fdl6dpkycs1p00000gn/T/ipykernel_41774/148888513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margument_with_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margument_with_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_data/arg_detect_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_data/arg_detect_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m                 \u001b[0mPrevious\u001b[0m \u001b[0mversions\u001b[0m \u001b[0mforwarded\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m'gzip'\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m                 \u001b[0;31m`\u001b[0m\u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mprevented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3467\u001b[0m                 \u001b[0msetting\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmtime\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mto\u001b[0m \u001b[0minclude\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mopening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maddition\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m\"dataframe\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         \u001b[0mnotebook\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0mWhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mHTML\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0mborder\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibwriters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mCompressionOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mFilePath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilePath' from 'pandas._typing' (/Users/danielbradley/opt/anaconda3/lib/python3.8/site-packages/pandas/_typing.py)"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"processed_data/dataset_arg_detect_wiki.csv\")\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.data.values\n",
        "#Create the labels\n",
        "labels = df.target.values\n",
        "\n",
        "# fine tune the existing model\n",
        "nlp = spacy.load('en_core_web_trf')\n",
        "argument_with_labels = list(zip(sentences,labels))\n",
        "\n",
        "#Shuffle and split the data\n",
        "random.shuffle(argument_with_labels)\n",
        "train_data = argument_with_labels[:int(len(argument_with_labels)*0.8)]\n",
        "dev_data = argument_with_labels[int(len(argument_with_labels)*0.8):]\n",
        "\n",
        "pd.DataFrame(train_data, columns = ['feature', 'target']).to_csv('processed_data/arg_detect_train.csv')\n",
        "pd.DataFrame(dev_data, columns = ['feature', 'target']).to_csv('processed_data/arg_detect_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z4i7rcILQrGw"
      },
      "outputs": [],
      "source": [
        "# User function for converting the train and test dataset into spaCy document\n",
        "\n",
        "def document(data):\n",
        "#Creating empty list called \"text\"  \n",
        "  text = []\n",
        "  for doc, label in nlp.pipe(data, as_tuples = True):\n",
        "    if label == 1:\n",
        "      doc.cats['LABEL'] = 1.0\n",
        "      doc.cats['NOT_LABEL'] = 0.0\n",
        "    else:\n",
        "      doc.cats['LABEL'] = 0.0\n",
        "      doc.cats['NOT_LABEL'] = 1.0\n",
        "#Adding the doc into the list 'text'\n",
        "    text.append(doc)\n",
        "  return(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IVhLmTtRkcu",
        "outputId": "7b943b2a-b6d0-439e-cb0b-44bc043d4e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duration: 4:45:36.125913\n"
          ]
        }
      ],
      "source": [
        "# Calculate the time for converting into binary document for train dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the train dataset into function 'document'\n",
        "train_docs = document(train_data)\n",
        "\n",
        "#Creating binary document using DocBin function in spaCy\n",
        "doc_bin = DocBin(docs = train_docs)\n",
        "\n",
        "#Saving the binary document as train.spacy\n",
        "doc_bin.to_disk(\"processed_data/arg_detect/train.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for train dataset\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-McplE1lS0RO",
        "outputId": "7d1388c9-2e63-4071-a926-9ff21625c5dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duration: 0:32:28.519081\n"
          ]
        }
      ],
      "source": [
        "# Calculate the time for converting into binary document for test dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the test dataset into function 'document'\n",
        "test_docs = document(dev_data)\n",
        "doc_bin = DocBin(docs = test_docs)\n",
        "doc_bin.to_disk(\"processed_data/arg_detect/valid.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for test dataset\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 2: Argument quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 2: Claim stance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#3: Argument stance detection dataset\n",
        "dataset_arg_stance = pd.read_csv('data/IBM_Debater_(R)_CS_EACL-2017.v1/claim_stance_dataset_v1.csv')\n",
        "stance_df = dataset_arg_stance[['topicText','claims.stance','claims.claimCorrectedText']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/9z/tw9j8p_n7w3fdl6dpkycs1p00000gn/T/ipykernel_41774/2515234827.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  stance_df['feature'] = stance_df['claims.claimCorrectedText']+' '+stance_df['topicText']\n"
          ]
        }
      ],
      "source": [
        "#Define the feature and target\n",
        "stance_df['feature'] = stance_df['claims.claimCorrectedText']+' '+stance_df['topicText']\n",
        "stance_df['target'] = stance_df['claims.stance'].apply(lambda x: 0 if x == 'CON' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessed_stance_df = stance_df[['feature', 'target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Exposure to violent video games causes at leas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>video game violence is not related to serious ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>some violent video games may actually have a p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>exposure to violent video games causes both sh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Violent video games increase the violent tende...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>democracies have ever been found incompatible ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2390</th>\n",
              "      <td>democracy cannot subsist long nor be carried f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2391</th>\n",
              "      <td>Democracy in general is criticized for ignorin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2392</th>\n",
              "      <td>democracy and freedom are indispensable ingred...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2393</th>\n",
              "      <td>democracy cannot be imposed from outside This ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2394 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                feature  target\n",
              "0     Exposure to violent video games causes at leas...       1\n",
              "1     video game violence is not related to serious ...       0\n",
              "2     some violent video games may actually have a p...       0\n",
              "3     exposure to violent video games causes both sh...       1\n",
              "4     Violent video games increase the violent tende...       1\n",
              "...                                                 ...     ...\n",
              "2389  democracies have ever been found incompatible ...       0\n",
              "2390  democracy cannot subsist long nor be carried f...       0\n",
              "2391  Democracy in general is criticized for ignorin...       0\n",
              "2392  democracy and freedom are indispensable ingred...       1\n",
              "2393  democracy cannot be imposed from outside This ...       0\n",
              "\n",
              "[2394 rows x 2 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessed_stance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"processed_data/dataset_arg_detect_wiki.csv\")\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = list(preprocessed_stance_df['feature'])\n",
        "#Create the labels\n",
        "labels = list(preprocessed_stance_df['target'])\n",
        "\n",
        "#Zip them together for use as a tuple\n",
        "argument_with_labels = list(zip(sentences,labels))\n",
        "\n",
        "#Shuffle and split the data\n",
        "random.shuffle(argument_with_labels)\n",
        "train_data = argument_with_labels[:int(len(argument_with_labels)*0.8)]\n",
        "dev_data = argument_with_labels[int(len(argument_with_labels)*0.8):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ran this once to create test and train sets\n",
        "# pd.DataFrame(train_data, columns = ['feature', 'target']).to_csv('processed_data/claim_stance/train.csv')\n",
        "# pd.DataFrame(dev_data, columns = ['feature', 'target']).to_csv('processed_data/claim_stance/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load the nlp model\n",
        "nlp = spacy.load('en_core_web_trf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IVhLmTtRkcu",
        "outputId": "7b943b2a-b6d0-439e-cb0b-44bc043d4e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duration: 0:07:07.360077\n"
          ]
        }
      ],
      "source": [
        "# Calculate the time for converting into binary document for train dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the train dataset into function 'document'\n",
        "train_docs = document(train_data)\n",
        "\n",
        "#Creating binary document using DocBin function in spaCy\n",
        "doc_bin = DocBin(docs = train_docs)\n",
        "\n",
        "#Saving the binary document as train.spacy\n",
        "doc_bin.to_disk(\"processed_data/claim_stance/train.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for train dataset\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-McplE1lS0RO",
        "outputId": "7d1388c9-2e63-4071-a926-9ff21625c5dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duration: 0:01:50.709221\n"
          ]
        }
      ],
      "source": [
        "# Calculate the time for converting into binary document for test dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the test dataset into function 'document'\n",
        "test_docs = document(dev_data)\n",
        "doc_bin = DocBin(docs = test_docs)\n",
        "doc_bin.to_disk(\"processed_data/claim_stance/valid.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for test dataset\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "T0ZsAWAXmPhz"
      ],
      "name": "Sophie_training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "0c1f5ce8eed932a4317a88fdfc83317a84584de98614c992901b7b196b5e3487"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
